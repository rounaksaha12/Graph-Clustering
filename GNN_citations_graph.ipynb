{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNqIsPCJk61z8BL0AgQIMJE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rounaksaha12/Graph-Clustering/blob/main/GNN_citations_graph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "492yV99Dv7Sh"
      },
      "outputs": [],
      "source": [
        "!mkdir graph_info"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir outputs"
      ],
      "metadata": {
        "id": "58wqkFAXwLMI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scipy --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xf_5kZRE0wYO",
        "outputId": "54b8cbae-3d19-4ccf-ab58-f944876116a6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (1.7.3)\n",
            "Collecting scipy\n",
            "  Downloading scipy-1.10.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.8/dist-packages (from scipy) (1.21.6)\n",
            "Installing collected packages: scipy\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.7.3\n",
            "    Uninstalling scipy-1.7.3:\n",
            "      Successfully uninstalled scipy-1.7.3\n",
            "Successfully installed scipy-1.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "id": "mhN7uEo5mFqa",
        "outputId": "5d084669-3371-4aaa-ab17-645179c42d75"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (3.2.2)\n",
            "Collecting matplotlib\n",
            "  Downloading matplotlib-3.6.2-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (7.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (21.3)\n",
            "Collecting contourpy>=1.0.1\n",
            "  Downloading contourpy-1.0.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.0/296.0 KB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m965.4/965.4 KB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n",
            "Installing collected packages: fonttools, contourpy, matplotlib\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "Successfully installed contourpy-1.0.6 fonttools-4.38.0 matplotlib-3.6.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -c \"import torch; print(torch.__version__)\"\n",
        "!python -c \"import torch; print(torch.version.cuda)\"\n",
        "!pip install pyg-lib torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-1.13.0+cu116.html\n",
        "!pip install torch-geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vw-aDYWM3Uit",
        "outputId": "03517351-8070-4bd9-88c7-d281e5cf86d3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.13.0+cu116\n",
            "11.6\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.13.0+cu116.html\n",
            "Collecting pyg-lib\n",
            "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/pyg_lib-0.1.0%2Bpt113cu116-cp38-cp38-linux_x86_64.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_scatter-2.1.0%2Bpt113cu116-cp38-cp38-linux_x86_64.whl (9.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_sparse-0.6.16%2Bpt113cu116-cp38-cp38-linux_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch-sparse) (1.10.0)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.8/dist-packages (from scipy->torch-sparse) (1.21.6)\n",
            "Installing collected packages: torch-scatter, pyg-lib, torch-sparse\n",
            "Successfully installed pyg-lib-0.1.0+pt113cu116 torch-scatter-2.1.0+pt113cu116 torch-sparse-0.6.16+pt113cu116\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.2.0.tar.gz (564 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m565.0/565.0 KB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (4.64.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (2.25.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.0.2)\n",
            "Collecting psutil>=5.8.0\n",
            "  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.2/280.2 KB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (2022.12.7)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch-geometric) (1.2.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.2.0-py3-none-any.whl size=773302 sha256=f7a739c0241e4e5ae22656cd40b80de3b70d91f609dc13115dd4730b8b079dcb\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/a3/20/198928106d3169865ae73afcbd3d3d1796cf6b429b55c65378\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: psutil, torch-geometric\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "Successfully installed psutil-5.9.4 torch-geometric-2.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "psutil"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import networkx as nx"
      ],
      "metadata": {
        "id": "10r98RgvwQJF"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intended_cluster_count=9 #choosing cluster count with highest silhoutte index\n",
        "\n",
        "cluster_assignments_df=pd.read_csv(f'./outputs/cluster_assignments_ncluster_{intended_cluster_count}.csv')\n",
        "cluster_labels=cluster_assignments_df.to_numpy()[:,1]\n",
        "node_count=len(cluster_labels)\n",
        "print(node_count)\n",
        "print(cluster_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFo6YVTxwqCS",
        "outputId": "2b204df3-8286-4b02-d318-667b60b60fad"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2114\n",
            "[2 7 3 ... 2 5 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mapped_edge_list=pd.read_csv('./graph_info/edge_info.txt',delimiter='\\t').to_numpy()\n",
        "mapped_edge_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOwqYk8jw6zm",
        "outputId": "ed04eaff-98e3-4411-d593-6d58825c910a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,  140],\n",
              "       [   1, 1630],\n",
              "       [   2, 1038],\n",
              "       ...,\n",
              "       [2027, 2047],\n",
              "       [2027, 2050],\n",
              "       [2059, 2079]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "G_mapped=nx.Graph()\n",
        "G_mapped.add_nodes_from(np.arange(node_count))\n",
        "G_mapped.add_edges_from(mapped_edge_list)"
      ],
      "metadata": {
        "id": "R2JPeIxTxfpn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(G_mapped.number_of_nodes())\n",
        "print(G_mapped.number_of_edges())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EV_wOReLz4MJ",
        "outputId": "12fe748b-e479-42d3-dd8d-122c327bc447"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2114\n",
            "2160\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from torch_geometric.data import InMemoryDataset, Data\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch_geometric.transforms as T"
      ],
      "metadata": {
        "id": "XgU7VDse0AkV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adj = nx.to_scipy_sparse_array(G_mapped).tocoo()\n",
        "row = torch.from_numpy(adj.row.astype(np.int64)).to(torch.long)\n",
        "col = torch.from_numpy(adj.col.astype(np.int64)).to(torch.long)\n",
        "edge_index = torch.stack([row, col], dim=0)"
      ],
      "metadata": {
        "id": "zZgJfQWf1dVP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# custom dataset\n",
        "class CitationsDataset(InMemoryDataset):\n",
        "    def __init__(self, G, edge_index, num_classes, cluster_labels,transform=None):\n",
        "        super(CitationsDataset, self).__init__('.', transform, None, None)\n",
        "        data = Data(edge_index=edge_index)\n",
        "        n_nodes = G.number_of_nodes()\n",
        "        data.num_nodes = n_nodes\n",
        "        \n",
        "        # input feature: node id\n",
        "        data.x = torch.arange(n_nodes)\n",
        "        \n",
        "        # labels\n",
        "        y = torch.from_numpy(cluster_labels).type(torch.long)\n",
        "        data.y = y.clone().detach()\n",
        "        \n",
        "        data.num_classes = num_classes\n",
        "\n",
        "        # splitting the data into train, validation and test\n",
        "        X_train, X_test, y_train, y_test = train_test_split(pd.Series(list(G.nodes())), \n",
        "                                                            pd.Series(cluster_labels),\n",
        "                                                            test_size=0.20, \n",
        "                                                            random_state=42)\n",
        "        \n",
        "        \n",
        "        \n",
        "        # create train and test masks for data\n",
        "        train_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
        "        test_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
        "        train_mask[X_train.index] = True\n",
        "        test_mask[X_test.index] = True\n",
        "        data['train_mask'] = train_mask\n",
        "        data['test_mask'] = test_mask\n",
        "\n",
        "        self.data, self.slices = self.collate([data])\n",
        "\n",
        "    def _download(self):\n",
        "        return\n",
        "\n",
        "    def _process(self):\n",
        "        return\n",
        "\n",
        "    def __repr__(self):\n",
        "        return '{}()'.format(self.__class__.__name__)"
      ],
      "metadata": {
        "id": "TK7pbz8P5vMM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv"
      ],
      "metadata": {
        "id": "7hE11Hxd8XJI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes=np.argmax(cluster_labels)+1\n",
        "citations_data=CitationsDataset(G_mapped,edge_index,num_classes,cluster_labels)[0]\n",
        "# print(citations_dataset)"
      ],
      "metadata": {
        "id": "Y69-3EHE8KYd"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the network"
      ],
      "metadata": {
        "id": "B8HfONiVyB83"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "      def __init__(self,num_nodes,num_classes,embed_dim=32):\n",
        "          super(Net,self).__init__()\n",
        "          self.num_nodes=num_nodes\n",
        "          self.embed_dim=embed_dim\n",
        "          self.embed=nn.Embedding(num_nodes,embed_dim)\n",
        "          self.conv1=GCNConv(embed_dim,64)\n",
        "          self.conv2=GCNConv(64,int(num_classes))\n",
        "\n",
        "      def forward(self,x,edge_index):\n",
        "          x=self.embed(x)\n",
        "          x=F.relu(self.conv1(x,edge_index))\n",
        "          x = F.dropout(x, training=self.training)\n",
        "          x = self.conv2(x, edge_index)\n",
        "          return F.log_softmax(x, dim=1)\n",
        "\n",
        "      def decode(self,x,edge_index):\n",
        "          x=F.relu(self.conv1(x,edge_index))\n",
        "          x = F.dropout(x, training=self.training)\n",
        "          x = self.conv2(x, edge_index)\n",
        "          return F.log_softmax(x, dim=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "imeSk7vs-xt4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "citations_data=citations_data.to(device)\n",
        "model=Net(node_count,num_classes,2).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=1e-2, weight_decay=5e-4)"
      ],
      "metadata": {
        "id": "UjVwcYTwBgoL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "oprRjchUaK5n"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "OOMGiTKmx9nL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_cnt=500\n",
        "\n",
        "def accuracy(output, labels):\n",
        "    preds = output.max(1)[1].type_as(labels)\n",
        "    correct = preds.eq(labels).double()\n",
        "    correct = correct.sum()\n",
        "    return correct / len(labels)\n",
        "\n",
        "t_start = time.time()\n",
        "\n",
        "# train loop\n",
        "for epoch in tqdm(range(epoch_cnt)):\n",
        "    t = time.time()\n",
        "\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    output = model(citations_data.x,edge_index)\n",
        "    loss_train = F.nll_loss(output[citations_data.train_mask], citations_data.y[citations_data.train_mask])\n",
        "    acc_train = accuracy(output[citations_data.train_mask], citations_data.y[citations_data.train_mask])\n",
        "    \n",
        "    loss_train.backward()\n",
        "    \n",
        "    optimizer.step()\n",
        "    \n",
        "    model.eval()\n",
        "    output = model(citations_data.x,edge_index)\n",
        "    \n",
        "    loss_val = F.nll_loss(output[citations_data.test_mask], citations_data.y[citations_data.test_mask])\n",
        "    acc_val = accuracy(output[citations_data.test_mask], citations_data.y[citations_data.test_mask])\n",
        "    \n",
        "    if not epoch % 10:\n",
        "      # Print all the results and the time required\n",
        "      print('Epoch: {:04d}'.format(epoch+1),\n",
        "            'loss_train: {:.4f}'.format(loss_train.item()),\n",
        "            'acc_train: {:.4f}'.format(acc_train.item()),\n",
        "            'loss_val: {:.4f}'.format(loss_val.item()),\n",
        "            'acc_val: {:.4f}'.format(acc_val.item()),\n",
        "            'time: {:.4f}s'.format(time.time() - t))\n",
        "    \n",
        "print(\"Model training is complete!\")\n",
        "print(\"Total model training time: {:.4f}s\".format(time.time() - t_start))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZj3RNo8ISb0",
        "outputId": "df0c014c-c219-46c8-feaa-106b28131a1e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|▏         | 7/500 [00:00<00:18, 26.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0001 loss_train: 2.4955 acc_train: 0.0852 loss_val: 2.4602 acc_val: 0.1253 time: 0.1984s\n",
            "Epoch: 0011"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 17/500 [00:00<00:12, 38.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loss_train: 2.2670 acc_train: 0.1892 loss_val: 2.2784 acc_val: 0.1844 time: 0.0189s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 28/500 [00:00<00:10, 45.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0021 loss_train: 2.1565 acc_train: 0.2052 loss_val: 2.1836 acc_val: 0.1986 time: 0.0201s\n",
            "Epoch: 0031 loss_train: 2.0426 acc_train: 0.2383 loss_val: 2.0766 acc_val: 0.2317 time: 0.0179s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|▉         | 48/500 [00:01<00:09, 46.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0041 loss_train: 1.8725 acc_train: 0.3146 loss_val: 1.9043 acc_val: 0.3050 time: 0.0180s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 58/500 [00:01<00:09, 45.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0051 loss_train: 1.5924 acc_train: 0.4276 loss_val: 1.6459 acc_val: 0.4421 time: 0.0199s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|█▎        | 68/500 [00:01<00:09, 45.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0061 loss_train: 1.2855 acc_train: 0.5677 loss_val: 1.3448 acc_val: 0.5603 time: 0.0225s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 78/500 [00:01<00:09, 45.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0071 loss_train: 0.9758 acc_train: 0.6765 loss_val: 1.0618 acc_val: 0.6643 time: 0.0251s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 88/500 [00:02<00:08, 47.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0081 loss_train: 0.7604 acc_train: 0.7700 loss_val: 0.8276 acc_val: 0.7541 time: 0.0217s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|█▉        | 98/500 [00:02<00:08, 47.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0091 loss_train: 0.5308 acc_train: 0.8415 loss_val: 0.6602 acc_val: 0.8109 time: 0.0227s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|██▏       | 108/500 [00:02<00:08, 46.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0101 loss_train: 0.3950 acc_train: 0.9007 loss_val: 0.5425 acc_val: 0.8511 time: 0.0224s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▎       | 118/500 [00:02<00:08, 45.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0111 loss_train: 0.2897 acc_train: 0.9296 loss_val: 0.4693 acc_val: 0.8605 time: 0.0220s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 128/500 [00:02<00:08, 46.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0121 loss_train: 0.2123 acc_train: 0.9539 loss_val: 0.4241 acc_val: 0.8771 time: 0.0203s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|██▊       | 139/500 [00:03<00:07, 47.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0131 loss_train: 0.1772 acc_train: 0.9675 loss_val: 0.3911 acc_val: 0.8771 time: 0.0214s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|██▉       | 149/500 [00:03<00:07, 46.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0141 loss_train: 0.1428 acc_train: 0.9781 loss_val: 0.3655 acc_val: 0.8913 time: 0.0257s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 160/500 [00:03<00:07, 47.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0151 loss_train: 0.1206 acc_train: 0.9805 loss_val: 0.3495 acc_val: 0.8936 time: 0.0227s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 165/500 [00:03<00:07, 45.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0161 loss_train: 0.1019 acc_train: 0.9846 loss_val: 0.3287 acc_val: 0.9007 time: 0.0246s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▌      | 177/500 [00:03<00:06, 48.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0171 loss_train: 0.0927 acc_train: 0.9917 loss_val: 0.3113 acc_val: 0.9007 time: 0.0213s\n",
            "Epoch: 0181 loss_train: 0.0834 acc_train: 0.9947 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 37%|███▋      | 187/500 [00:04<00:06, 48.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_val: 0.2928 acc_val: 0.9125 time: 0.0180s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 39%|███▉      | 197/500 [00:04<00:06, 47.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0191 loss_train: 0.0780 acc_train: 0.9935 loss_val: 0.2758 acc_val: 0.9196 time: 0.0240s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 208/500 [00:04<00:06, 48.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0201 loss_train: 0.0708 acc_train: 0.9935 loss_val: 0.2593 acc_val: 0.9243 time: 0.0238s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 44%|████▎     | 218/500 [00:04<00:06, 46.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0211 loss_train: 0.0625 acc_train: 0.9947 loss_val: 0.2419 acc_val: 0.9314 time: 0.0201s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 46%|████▌     | 229/500 [00:05<00:05, 48.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0221 loss_train: 0.0615 acc_train: 0.9970 loss_val: 0.2319 acc_val: 0.9338 time: 0.0204s\n",
            "Epoch: 0231 loss_train: 0.0580 acc_train: 0.9970 loss_val: 0.2140 acc_val: 0.9456 time: 0.0175s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|████▉     | 249/500 [00:05<00:05, 48.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0241 loss_train: 0.0593 acc_train: 0.9976 loss_val: 0.1995 acc_val: 0.9504 time: 0.0193s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|█████▏    | 259/500 [00:05<00:05, 48.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0251 loss_train: 0.0526 acc_train: 0.9982 loss_val: 0.1816 acc_val: 0.9527 time: 0.0200s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 54%|█████▍    | 270/500 [00:05<00:04, 48.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0261 loss_train: 0.0537 acc_train: 0.9965 loss_val: 0.1685 acc_val: 0.9574 time: 0.0280s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 56%|█████▌    | 280/500 [00:06<00:04, 47.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0271 loss_train: 0.0501 acc_train: 0.9982 loss_val: 0.1621 acc_val: 0.9622 time: 0.0230s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 285/500 [00:06<00:04, 44.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0281 loss_train: 0.0556 acc_train: 0.9970 loss_val: 0.1512 acc_val: 0.9645 time: 0.0252s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 300/500 [00:06<00:04, 46.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0291 loss_train: 0.0481 acc_train: 0.9994 loss_val: 0.1437 acc_val: 0.9716 time: 0.0216s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 62%|██████▏   | 310/500 [00:06<00:04, 45.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0301 loss_train: 0.0561 acc_train: 0.9941 loss_val: 0.1347 acc_val: 0.9740 time: 0.0247s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 320/500 [00:06<00:03, 47.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0311 loss_train: 0.0517 acc_train: 0.9970 loss_val: 0.1279 acc_val: 0.9764 time: 0.0239s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▌   | 330/500 [00:07<00:03, 47.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0321 loss_train: 0.0486 acc_train: 0.9994 loss_val: 0.1279 acc_val: 0.9787 time: 0.0242s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 335/500 [00:07<00:03, 46.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0331 loss_train: 0.0434 acc_train: 1.0000 loss_val: 0.1188 acc_val: 0.9811 time: 0.0248s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 69%|██████▉   | 346/500 [00:07<00:03, 47.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0341 loss_train: 0.0472 acc_train: 0.9982 loss_val: 0.1138 acc_val: 0.9811 time: 0.0219s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 71%|███████   | 356/500 [00:07<00:03, 47.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0351 loss_train: 0.0453 acc_train: 0.9982 loss_val: 0.1085 acc_val: 0.9858 time: 0.0212s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 73%|███████▎  | 367/500 [00:07<00:02, 48.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0361 loss_train: 0.0481 acc_train: 0.9988 loss_val: 0.1057 acc_val: 0.9882 time: 0.0216s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▌  | 378/500 [00:08<00:02, 48.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0371 loss_train: 0.0392 acc_train: 0.9994 loss_val: 0.1086 acc_val: 0.9858 time: 0.0237s\n",
            "Epoch: 0381 loss_train: 0.0379 acc_train: 0.9994 loss_val: 0.1029 acc_val: 0.9858 time: 0.0183s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 400/500 [00:08<00:02, 48.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0391 loss_train: 0.0459 acc_train: 0.9994 loss_val: 0.1008 acc_val: 0.9882 time: 0.0200s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 82%|████████▏ | 410/500 [00:08<00:01, 47.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0401 loss_train: 0.0454 acc_train: 1.0000 loss_val: 0.0944 acc_val: 0.9882 time: 0.0263s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▍ | 421/500 [00:09<00:01, 48.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0411 loss_train: 0.0438 acc_train: 0.9994 loss_val: 0.0996 acc_val: 0.9882 time: 0.0254s\n",
            "Epoch: 0421 loss_train: 0.0445 acc_train: 1.0000 loss_val: 0.0998 acc_val: 0.9882 time: 0.0182s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 87%|████████▋ | 436/500 [00:09<00:01, 46.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0431 loss_train: 0.0428 acc_train: 0.9988 loss_val: 0.0948 acc_val: 0.9905 time: 0.0208s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 89%|████████▉ | 446/500 [00:09<00:01, 46.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0441 loss_train: 0.0424 acc_train: 0.9994 loss_val: 0.0941 acc_val: 0.9882 time: 0.0222s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 91%|█████████ | 456/500 [00:09<00:00, 45.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0451 loss_train: 0.0414 acc_train: 0.9994 loss_val: 0.0936 acc_val: 0.9882 time: 0.0222s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 93%|█████████▎| 466/500 [00:10<00:00, 46.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0461 loss_train: 0.0453 acc_train: 0.9982 loss_val: 0.0914 acc_val: 0.9905 time: 0.0219s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▌| 477/500 [00:10<00:00, 47.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0471 loss_train: 0.0418 acc_train: 0.9994 loss_val: 0.0932 acc_val: 0.9905 time: 0.0230s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 97%|█████████▋| 487/500 [00:10<00:00, 47.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0481 loss_train: 0.0424 acc_train: 0.9988 loss_val: 0.0923 acc_val: 0.9882 time: 0.0220s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [00:10<00:00, 46.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0491 loss_train: 0.0402 acc_train: 1.0000 loss_val: 0.0933 acc_val: 0.9905 time: 0.0242s\n",
            "Model training is complete!\n",
            "Total model training time: 10.7827s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting the embedding space"
      ],
      "metadata": {
        "id": "KcLLCSWKn34F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
        "\n",
        "def plot_examples(color_mat,colormaps):\n",
        "    \"\"\"\n",
        "    Helper function to plot color_mat with associated colormap.\n",
        "    \"\"\"    \n",
        "    fig, axs = plt.subplots(constrained_layout=True, squeeze=False)\n",
        "    ax=axs.flat[0]\n",
        "    cmap=colormaps\n",
        "    psm = ax.pcolormesh(color_mat, cmap=cmap, rasterized=True, vmin=0, vmax=8)\n",
        "    fig.colorbar(psm, ax=ax)\n",
        "    plt.savefig('graph.jpeg')\n",
        "\n",
        "for embedding_mat in model.embed.parameters():\n",
        "  print(embedding_mat)\n",
        "  max_x=torch.max(embedding_mat[:,0]).detach()\n",
        "  min_x=torch.min(embedding_mat[:,0]).detach()\n",
        "  max_y=torch.max(embedding_mat[:,1]).detach()\n",
        "  min_y=torch.min(embedding_mat[:,1]).detach()\n",
        "\n",
        "grid_size=500\n",
        "x_step=(max_x-min_x)/grid_size\n",
        "y_step=(max_y-min_y)/grid_size\n",
        "color_mat=np.empty((grid_size,grid_size))\n",
        "\n",
        "\n",
        "for i in tqdm(range(grid_size)):\n",
        "  for j in range(grid_size):\n",
        "    emb_x=min_x+x_step*i\n",
        "    emb_y=min_y+y_step*j\n",
        "    dummy_input=torch.zeros((node_count,2),dtype=torch.float32)\n",
        "    dummy_input[0][0]=emb_x\n",
        "    dummy_input[0][1]=emb_y\n",
        "    color_mat[i][j]=torch.argmax(model.decode(dummy_input,edge_index)[0]).item()\n",
        "\n",
        "print(color_mat)\n",
        "\n",
        "viridis = mpl.colormaps['viridis'].resampled(256)\n",
        "plot_examples(color_mat,viridis)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637
        },
        "id": "Dp2gvoTnNPIM",
        "outputId": "2c13c0f0-c7d4-45fb-d5ed-bb64e8431280"
      },
      "execution_count": 18,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.2450, -0.1919],\n",
            "        [-0.1321,  0.2692],\n",
            "        [ 0.1151,  0.2090],\n",
            "        ...,\n",
            "        [-0.0951, -0.0605],\n",
            "        [ 0.3422,  0.1134],\n",
            "        [ 0.1010,  0.2289]], requires_grad=True)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [23:48<00:00,  2.86s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[4. 4. 4. ... 7. 7. 7.]\n",
            " [4. 4. 4. ... 7. 7. 7.]\n",
            " [4. 4. 4. ... 7. 7. 7.]\n",
            " ...\n",
            " [6. 6. 6. ... 3. 3. 3.]\n",
            " [6. 6. 6. ... 3. 3. 3.]\n",
            " [6. 6. 6. ... 3. 3. 3.]]\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lkPf-yPOiRl_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}